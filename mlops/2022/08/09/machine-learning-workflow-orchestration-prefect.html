<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect | Isaac Kargar</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Machine learning workflow orchestration using Prefect." />
<meta property="og:description" content="Machine learning workflow orchestration using Prefect." />
<link rel="canonical" href="https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html" />
<meta property="og:url" content="https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html" />
<meta property="og:site_name" content="Isaac Kargar" />
<meta property="og:image" content="https://kargarisaac.github.io/blog/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-09T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect","dateModified":"2022-08-09T00:00:00-05:00","datePublished":"2022-08-09T00:00:00-05:00","description":"Machine learning workflow orchestration using Prefect.","image":"https://kargarisaac.github.io/blog/images/some_folder/your_image.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html"},"@type":"BlogPosting","url":"https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://kargarisaac.github.io/blog/feed.xml" title="Isaac Kargar" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','G-7C8WW0BBJ4','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect | Isaac Kargar</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Machine learning workflow orchestration using Prefect." />
<meta property="og:description" content="Machine learning workflow orchestration using Prefect." />
<link rel="canonical" href="https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html" />
<meta property="og:url" content="https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html" />
<meta property="og:site_name" content="Isaac Kargar" />
<meta property="og:image" content="https://kargarisaac.github.io/blog/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-09T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect","dateModified":"2022-08-09T00:00:00-05:00","datePublished":"2022-08-09T00:00:00-05:00","description":"Machine learning workflow orchestration using Prefect.","image":"https://kargarisaac.github.io/blog/images/some_folder/your_image.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html"},"@type":"BlogPosting","url":"https://kargarisaac.github.io/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://kargarisaac.github.io/blog/feed.xml" title="Isaac Kargar" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','G-7C8WW0BBJ4','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Isaac Kargar</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">MLOps project - part 2a: Machine Learning Workflow Orchestration using Prefect</h1><p class="page-description">Machine learning workflow orchestration using Prefect.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-09T00:00:00-05:00" itemprop="datePublished">
        Aug 9, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      18 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/kargarisaac/blog/tree/master/_notebooks/2022-08-09-machine-learning-workflow-orchestration-prefect.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/kargarisaac/blog/master?filepath=_notebooks%2F2022-08-09-machine-learning-workflow-orchestration-prefect.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/kargarisaac/blog/blob/master/_notebooks/2022-08-09-machine-learning-workflow-orchestration-prefect.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Prefect">Prefect </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-08-09-machine-learning-workflow-orchestration-prefect.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the previous blog post, we learned how to use MLflow to train a model and track experiments.
In the second post of this series, we will convert the code from the previous phase into a machine learning pipeline. I'll demonstrate how to complete the task using two popular tools: Prefect and ZenML. There are several incredible tools that we cannot include in this article, such as Flyte, Kale, Aro, etc.</p>
<p>We begin with Prefect in this post and ZenML in the next one.</p>
<p>But why do our machine learning services need a pipeline? The ZenML manual describes it in detail [<a href="https://github.com/zenml-io/zenbytes">source</a>]:</p>
<blockquote>
<p>As an ML practitioner, you are probably familiar with building ML models using Scikit-learn, PyTorch, TensorFlow, or similar. An <strong><a href="https://docs.zenml.io/developer-guide/steps-and-pipelines">ML Pipeline</a></strong> is simply an extension, including other steps you would typically do before or after building a model, like data acquisition, preprocessing, model deployment, or monitoring. The ML pipeline essentially defines a step-by-step procedure of your work as an ML practitioner. Defining ML pipelines explicitly in code is great because:</p>
<ul>
<li>We can easily rerun all of our work, not just the model, eliminating bugs and making our models easier to reproduce.</li>
<li>Data and models can be versioned and tracked, so we can see at a glance which dataset a model was trained on and how it compares to other models.</li>
<li>If the entire pipeline is coded up, we can automate many operational tasks, like retraining and redeploying models when the underlying problem or data changes or rolling out new and improved models with CI/CD workflows.</li>
</ul>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We may have extensive preprocessing that we do not want to repeat every time we train a model, such as in the last blog post where we generated the <code>corpus</code> list.
We may also need to compare the performance of different models, or wish to deploy the model and monitor data and model performance. Here, ML pipelines come into play, allowing us to specify our workflows as a series of modular processes that can subsequently be combined.</p>
<p>Additionally, we may have a machine learning pipeline that we would like to execute every week. We can put it on a timetable, and if the machine learning model fails or the incoming data fails, we can analyze and resolve the issues.</p>
<p>Let's consider a standard machine learning pipeline:</p>
<p><img src="/blog/images/copied_from_nb/images/workflow-orchestration/1.png" alt="">
<em><a href="https://www.youtube.com/watch?v=eKzCjNXoCTc&amp;list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&amp;index=22">source</a></em></p>
<p>Initially, we have a postgresql database and possibly a process that writes data to a parquet file. Next, we use pandas to consume the parquet file and merge it with the API data we're pulling.
After training the model, we register the artifact and conduct experiments with MLflow; if specific conditions are met, we may deploy the model using Flask, for example.
Clearly, these phases are interconnected; if one fails, the entire pipeline will be impacted.
Failure can occur in even unforeseen ways. For example, inbound data is flawed, the API fails to connect at random, and the same is true for MLflow. Problems may arise if you are using a database to store MLflow artifacts, such as experiments. Workflow orchestration is intended to mitigate the impact of these problems and assist in their resolution.</p>
<p><img src="/blog/images/copied_from_nb/images/workflow-orchestration/2.png" alt="">
<em><a href="https://www.youtube.com/watch?v=eKzCjNXoCTc&amp;list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&amp;index=22">source</a></em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All of these will aid the organization and its developers in completing their tasks and locating issues more quickly, allowing them to devote their attention to something more vital.</p>
<p>Great! let's see how we can do it in practice. Our pipeline would be something like the following:</p>
<p><img src="/blog/images/copied_from_nb/images/workflow-orchestration/5.png" alt=""></p>
<p>For this project, we don't really need the pipeline, but I just want to show how we can create one. Based on the use case, it may be useful to have a pipeline. For example, if you have a data pipeline that you want to execute periodically or want to have a pipeline to train your machine learning model. Here I just want to show how you can do it if you need it in a project.</p>
<p>Let's see how Prefect can help us.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Prefect">
<a class="anchor" href="#Prefect" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prefect<a class="anchor-link" href="#Prefect"> </a>
</h1>
<p>Prefect is a too for the modern data stack to help you monitor, coordinate, and orchestrate dataflows between and across your applications. You can build pipelines, deploy them anywhere, and configure them remotely. If you move data, you probably need the following functionality [<a href="https://docs.prefect.io/">source</a>]:</p>
<ul>
<li>schedules</li>
<li>retries</li>
<li>logging</li>
<li>caching</li>
<li>notifications</li>
<li>observability</li>
</ul>
<p>Implementing all of these features for your dataflows is a lot of work and takes a lot of time — time that could be better used for functional code.</p>
<p>Prefect 2.0 offers all this functionality and more!</p>
<p>You can easily install Prefect using:</p>

<pre><code>pip install prefect</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I install Prefect <code>2.0.4</code>. I see that the API is changing so quickly and you need to use the same version if you want to follow along.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Prefect has some concepts that we try to introduce. You can check the documentation for more details. Here is a small intro for some of them from Prefect documentation:</p>
<ul>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/flows/">flow</a></strong>: Flows are like functions. They can take inputs, perform work, and return an output. In fact, you can turn any function into a Prefect flow by adding the <code>@flow</code> decorator. When a function becomes a flow, its behavior changes, giving it the following advantages:</p>
<ul>
<li>State transitions are reported to the API, allowing observation of flow execution.</li>
<li>Input arguments types can be validated.</li>
<li>Retries can be performed on failure.</li>
<li>Timeouts can be enforced to prevent unintentional, long-running workflows.</li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/tasks/">task</a></strong>: Tasks are functions: they can take inputs, perform work, and return an output. A Prefect task can do almost anything a Python function can do. Use the <code>@task</code> decorator to designate a function as a task. Calling the task from within a flow function creates a new task run</p>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/infrastructure/">Infrastructure</a></strong>: Users may specify an infrastructure block when creating a deployment. This block will be used to specify infrastructure for flow runs created by the deployment at runtime. Infrastructure can only be used with a deployment. When you run a flow directly by calling the flow yourself, you are responsible for the environment in which the flow executes. Infrastructure is attached to a deployment and is propagated to flow runs created for that deployment. Infrastructure is deserialized by the agent and it has two jobs:</p>
<ul>
<li>Create execution environment infrastructure for the flow run.</li>
<li>
<p>Run a Python command to start the prefect.engine in the infrastructure, which retrieves the flow from storage and executes the flow.</p>
</li>
<li>
<p>Infrastructure is specific to the environments in which flows will run. Prefect currently provides the following infrastructure types:</p>
<ul>
<li>
<em><a href="https://docs.prefect.io/api-ref/prefect/infrastructure/#prefect.infrastructure.process.Process">Process</a></em> runs flows in a local subprocess.</li>
<li>
<em><a href="https://docs.prefect.io/api-ref/prefect/infrastructure/#prefect.infrastructure.docker.DockerContainer">DockerContainer</a></em> runs flows in a Docker container.</li>
<li>
<em><a href="https://docs.prefect.io/api-ref/prefect/infrastructure/#prefect.infrastructure.kubernetes.KubernetesJob">KubernetesJob</a></em> runs flows in a Kubernetes Job.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/task-runners/">task runner</a></strong>: Task runners enable you to engage specific executors for Prefect tasks, such as for concurrent, parallel, or distributed execution of tasks. Task runners are not required for task execution. If you call a task function directly, the task executes as a regular Python function, without a task runner, and produces whatever result is returned by the function.</p>
<ul>
<li>
<p>Prefect currently provides the following built-in task runners:</p>
<ul>
<li>
<em>SequentialTaskRunner</em> can run tasks sequentially.</li>
<li>
<em>ConcurrentTaskRunner</em> can run tasks concurrently, allowing tasks to switch when blocking on IO. Tasks will be submitted to a thread pool maintained by anyio.</li>
</ul>
</li>
<li>
<p>In addition, the following Prefect-developed task runners for parallel or distributed task execution may be installed as Prefect Collections.</p>
<ul>
<li>
<em>DaskTaskRunner</em> can run tasks requiring parallel execution using dask.distributed.</li>
<li>
<em>RayTaskRunner</em> can run tasks requiring parallel execution using Ray.</li>
</ul>
</li>
<li>
<p>In our case, I don't want to use these features and just want to run tasks sequentially, which is the default setting.</p>
</li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/deployments/">Deployments</a></strong>: A deployment is a server-side concept that encapsulates a flow, allowing it to be scheduled and triggered via API. The deployment stores metadata about where your flow's code is stored and how your flow should be run.</p>
<ul>
<li>
<p>All Prefect flow runs are tracked by the API. The API does not require prior registration of flows. With Prefect, you can call a flow locally or in a remote environment, which will be tracked.</p>
</li>
<li>
<p>Creating a deployment for a Prefect workflow means packaging workflow code, settings, and infrastructure configuration so that the workflow can be managed via the Prefect API and run remotely by a Prefect agent.</p>
</li>
<li>
<p>When creating a deployment, a user must answer two basic questions:</p>
<ul>
<li>What instructions does the agent need to set up an execution environment for my workflow? For example, a workflow may have Python requirements, unique Kubernetes settings, or Docker networking configuration.</li>
<li>Where and how can the agent access the flow code?</li>
</ul>
</li>
<li>
<p>A deployment additionally enables you to:</p>
<ul>
<li>Schedule flow runs</li>
<li>Assign tags for filtering flow runs on work queues and in the Prefect UI</li>
<li>Assign custom parameter values for flow runs based on the deployment</li>
<li>Create ad-hoc flow runs from the API or Prefect UI</li>
<li>Upload flow files to a defined storage location for retrieval at run time</li>
</ul>
</li>
<li>Deployments can package your flow code and pass the manifest to the API — either Prefect Cloud or a local Prefect Orion server run with prefect orion start.</li>
<li>Here, I just run Prefect locally and do not do any deployment on Docker or Kubernetes or Cloud. I will discuss the possible options to run Prefect on Cloud later.</li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/storage/">Storage</a></strong>: Storage lets you configure how flow code for deployments is persisted and retrieved by Prefect agents. Anytime you build a deployment, a storage block is used to upload the entire directory containing your workflow code (along with supporting files) to its configured location. This helps ensure portability of your relative imports, configuration files, and more.</p>
<ul>
<li>
<p>Current options for deployment storage blocks include:</p>
<ul>
<li>
<em>Local File System</em>   Store data in a run's local file system.</li>
<li>
<em>Remote File System</em>  Store data in a any filesystem supported by fsspec.</li>
<li>
<em>AWS S3 Storage</em>  Store data in an AWS S3 bucket.</li>
<li>
<em>Google Cloud Storage</em>    Store data in a Google Cloud Platform (GCP) Cloud Storage bucket.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/work-queues/">Work Queues and Agents</a></strong>: Work queues and agents bridge the Prefect Orion orchestration environment with a user’s execution environment. Work queues define the work to be done, and agents poll a specific work queue for new work.</p>
<ul>
<li>You create a work queue on the server. Work queues collect scheduled runs for deployments that match their filter criteria.</li>
<li>You run an agent in the execution environment. Agents poll a specific work queue for new flow runs, take scheduled flow runs from the server, and deploy them for execution</li>
<li>
<p>Work queues organize work that agents can pick up to execute. Work queue configuration determines what work will be picked up.</p>
</li>
<li>
<p>Work queues contain scheduled runs from any deployments that match the queue criteria. Criteria is based on deployment tags — all runs for deployments that have the tags defined on the queue will be picked up.</p>
</li>
<li>
<p>These criteria can be modified at any time, and agent processes requesting work for a specific queue will only see matching flow runs.</p>
</li>
<li>
<p>Agent processes are lightweight polling services that get scheduled work from a work queue and deploy the corresponding flow runs.</p>
</li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.prefect.io/concepts/schedules/">Schedules</a></strong>: Schedules tell the Prefect API how to create new flow runs for you automatically on a specified cadence.</p>
<ul>
<li>You can add a schedule to any flow deployment. The Prefect Scheduler service periodically reviews every deployment and creates new flow runs according to the schedule configured for the deployment.</li>
<li>
<p>Prefect supports several types of schedules that cover a wide range of use cases and offer a large degree of customization:</p>
<ul>
<li>
<em>Cron</em> is most appropriate for users who are already familiar with cron from previous use.</li>
<li>
<em>Interval</em> is best suited for deployments that need to run at some consistent cadence that isn't related to absolute time.</li>
<li>
<em>RRule</em> is best suited for deployments that rely on calendar logic for simple recurring schedules, irregular intervals, exclusions, or day-of-month adjustments.</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will add Prefect to a Python script containing our code. I will continue with the Keras code from the previous post, although the method is identical for other Scikit-Learn packages. Essentially, we obtain the prior code, including all MLflow-related information, and convert it into functions as our pipeline steps. Converting the python functions to Prefect steps and flow is as easy as wrapping the function using <code>@task</code> and <code>@flow</code> decorators. In our case, the code for training the model might look as follows:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">'./corpora'</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"NLTK_DATA"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"./corpora"</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'stopwords'</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">prefect</span> <span class="kn">import</span> <span class="n">flow</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="nn">prefect.task_runners</span> <span class="kn">import</span> <span class="n">SequentialTaskRunner</span>

<span class="c1">## data loading</span>
<span class="nd">@task</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"read data"</span><span class="p">,</span> 
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">"data"</span><span class="p">],</span> 
    <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
    <span class="n">retry_delay_seconds</span><span class="o">=</span><span class="mi">60</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">'Womens Clothing E-Commerce Reviews.csv'</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="n">index_col</span> <span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Data loaded.</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="c1">## preprocess text</span>
<span class="nd">@task</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"preprocess data"</span><span class="p">,</span> 
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">"data"</span><span class="p">],</span> 
    <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
    <span class="n">retry_delay_seconds</span><span class="o">=</span><span class="mi">60</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">preprocess_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1">#check if data/corpus is created before or not</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">'data/corpus_y.pickle'</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Preprocessed data not found. Creating new data. </span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">~</span><span class="n">data</span><span class="p">[</span><span class="s1">'Review Text'</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()]</span>  <span class="c1">#Dropping columns which don't have any review</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">'Review Text'</span><span class="p">]]</span>
        <span class="n">X</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'Recommended IND'</span><span class="p">]</span>

        <span class="n">corpus</span> <span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">'[^a-zA-z]'</span><span class="p">,</span><span class="s1">' '</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="s1">'Review Text'</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">review</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="n">ps</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
            <span class="n">review</span> <span class="o">=</span><span class="p">[</span><span class="n">ps</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">review</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">'english'</span><span class="p">))]</span>
            <span class="n">review</span> <span class="o">=</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
            <span class="n">corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'data/corpus_y.pickle'</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">corpus</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">handle</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Preprocessed data found. Loading data. </span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'data/corpus_y.pickle'</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">corpus</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Data preprocessed.</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">y</span>

<span class="c1">## tokenization and dataset creation</span>
<span class="nd">@task</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"create dataset"</span><span class="p">,</span> 
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">"data"</span><span class="p">],</span> 
    <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
    <span class="n">retry_delay_seconds</span><span class="o">=</span><span class="mi">60</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">3000</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

    <span class="n">sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
    <span class="n">padded</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'post'</span><span class="p">)</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">padded</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Dataset created.</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tokenizer</span>

<span class="c1"># mlflow.tensorflow.autolog()</span>
<span class="nd">@task</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"tran model"</span><span class="p">,</span> 
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">"model"</span><span class="p">],</span> 
    <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
    <span class="n">retry_delay_seconds</span><span class="o">=</span><span class="mi">60</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]):</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
            <span class="c1">## model definition</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">3000</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>
            <span class="p">])</span>

            <span class="c1">## training</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
            <span class="n">callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
                <span class="n">monitor</span><span class="o">=</span><span class="s2">"val_loss"</span><span class="p">,</span>
                <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">,</span>
                <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

            <span class="n">mlflow</span><span class="o">.</span><span class="n">set_tag</span><span class="p">(</span><span class="s2">"developer"</span><span class="p">,</span> <span class="s2">"Isaac"</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">set_tag</span><span class="p">(</span><span class="s2">"algorithm"</span><span class="p">,</span> <span class="s2">"Deep Learning"</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">"train-data"</span><span class="p">,</span> <span class="s2">"Womens Clothing E-Commerce Reviews"</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">"embedding-dim"</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">"Fit model on training data"</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">X_train</span><span class="p">,</span>
                <span class="n">y_train</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>
                <span class="c1"># We pass some validation for</span>
                <span class="c1"># monitoring validation loss and metrics</span>
                <span class="c1"># at the end of each epoch</span>
                <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
            <span class="p">)</span>

            <span class="c1">## save model and tokenizer</span>
            <span class="c1"># model.save('models/model_dl.h5')</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'models/model_dl'</span><span class="p">)</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'models/tf_tokenizer.pickle'</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">local_path</span><span class="o">=</span><span class="s2">"models/tf_tokenizer.pickle"</span><span class="p">,</span> <span class="n">artifact_path</span><span class="o">=</span><span class="s2">"tokenizer_pickle"</span><span class="p">)</span>

            <span class="c1"># Evaluate the model on the test data using `evaluate`</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluate on test data"</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"test loss, test acc:"</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model training completed.</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>

<span class="nd">@flow</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"Sentiment-Analysis-Flow"</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">"A flow to run the pipeline for the customer sentiment analysis"</span><span class="p">,</span>
    <span class="n">task_runner</span><span class="o">=</span><span class="n">SequentialTaskRunner</span><span class="p">()</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tracking_uri</span> <span class="o">=</span> <span class="s2">"sqlite:///mlflow.db"</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"customer-sentiment-analysis"</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="n">tracking_uri</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">()</span>
    <span class="n">corpus</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">train_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When you trained the mode, you can go to MLflow UI and decide if you want to change the model in the <code>Production</code> stage or not. Then you can easily load the model in the <code>Production</code> stage using a code snippet like this and evaluate it as you wish (maybe creating another pipeline for that):</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlflow.tracking</span> <span class="kn">import</span> <span class="n">MlflowClient</span>

<span class="k">def</span> <span class="nf">get_best_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">client</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="sa">f</span><span class="s2">"models:/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">/production"</span><span class="p">,</span> <span class="n">dst_path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">mv</span> <span class="ow">in</span> <span class="n">client</span><span class="o">.</span><span class="n">search_model_versions</span><span class="p">(</span><span class="sa">f</span><span class="s2">"name='</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">'"</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">dict</span><span class="p">(</span><span class="n">mv</span><span class="p">)[</span><span class="s1">'current_stage'</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'Production'</span><span class="p">:</span>
            <span class="n">run_id</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">mv</span><span class="p">)[</span><span class="s1">'run_id'</span><span class="p">]</span>

    <span class="n">artifact_folder</span> <span class="o">=</span> <span class="s2">"models_pickle"</span> <span class="c1">#tokenizer_pickle</span>
    <span class="n">client</span><span class="o">.</span><span class="n">download_artifacts</span><span class="p">(</span><span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">artifact_folder</span><span class="p">,</span> <span class="n">dst_path</span><span class="o">=</span><span class="s1">'.'</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">artifact_folder</span><span class="si">}</span><span class="s2">/tf_tokenizer.pickle"</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model and tokenizer loaded.</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>

<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="c1"># Generate predictions (probabilities -- the output of the last layer)</span>
    <span class="c1"># on new data using `predict`</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Generate predictions for 3 samples"</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"predictions shape:"</span><span class="p">,</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">sample_string</span> <span class="o">=</span> <span class="s2">"I Will tell my friends for sure"</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
    <span class="n">padded_sample</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'post'</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">sample_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">padded_sample</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"model prediction for input: </span><span class="si">{</span><span class="n">sample_string</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">sample_predict</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">tracking_uri</span> <span class="o">=</span> <span class="s2">"sqlite:///mlflow.db"</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"customer-sentiment-analysis"</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">MlflowClient</span><span class="p">(</span><span class="n">tracking_uri</span><span class="o">=</span><span class="n">tracking_uri</span><span class="p">)</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_best_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">client</span><span class="p">)</span>
    <span class="n">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With wrapping the functions into Prefect, you will get more logs, which helps to observe and debug the pipeline. 
You can then run the following command to see the Prefect UI dashboard:</p>
<div class="highlight"><pre><span></span>prefect orion start
</pre></div>
<p>For our code, here is the screenshot:</p>
<p><img src="/blog/images/copied_from_nb/images/workflow-orchestration/4.png" alt="">
<!-- *[source](https://www.youtube.com/watch?v=eKzCjNXoCTc&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=22)* --></p>
<p>You can see the logs for different tasks and the flow of our code. You can also get much more information from the dashboard. So don't hesitate to play around.</p>
<p>There are a lot of interesting features in Prefect. I really like the concurrency, parallelization, and the async support.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can check the following videos to learn more about Prefect:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
</p>
<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/eKzCjNXoCTc" frameborder="0" allowfullscreen=""></iframe>
</center>

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/Yb6NJwI7bXw" frameborder="0" allowfullscreen=""></iframe>
</center>

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/MCFpURG506w" frameborder="0" allowfullscreen=""></iframe>
</center>


</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I wrote about another orchestration tool, AirFlow, before. You can find it <a href="https://kargarisaac.github.io/blog/data%20engineering/mlops/2022/01/25/data-engineering-w2.html">here</a>. Prefect is a really good alternative for that. It's much simpler and doesn't have all the complexities of using and debugging AirFlow. I highly recommend it for data workflows and ETL.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As I mentioned at the beginning of the post, we don't really need Prefect in this project and I will not deploy it on Cloud. But I discuss how I think it can be used on a Cloud like GCP.</p>
<p>The Prefect community in their slack suggested to use the Prefect Cloud if you really want to use it on Cloud, but I'm not interested in that solution, as I want to have everything on one Cloud like GCP.</p>
<p>One way to use Prefect on Cloud would be easily to have a VM and run Prefect there. Based on the tasks and how much computation they need, you can use more powerfull VMs like a VM with a GPU. In this case, if you want to have a schedule and want to do it using Prefect, I think you have to have the VM and Prefect running all the time, which would be costly if you have a VM with GPU. However, this would be OK for data pipelines and ETL. 
Check <a href="https://gist.github.com/TylerWanner/0b4b00f4701dae6ad0a98978efe01966">this gist</a> if you are interested in provisioning Prefect server on GCP using Terraform. It is just deploying on a VM again.</p>
<p>For flows that need GPU, one solution might be to have one VM to run Prefect Orion and one VM with GPU for running the flow. You can check <a href="https://cloud.google.com/compute/docs/instances/stop-start-instance#api_1">this page</a> to start and stop a VM using API. you can containerize your flow and use the VM to run it. You can also use Cloud Run and Cloud Function to run the flow and be triggered by the VM running the server. Note that Cloud Run and Cloud Function have some limitations in time and resources. VM might give you more flexibility.</p>
<p>The other solution would be to have Prefect flows on a VM with any spec you want and use Google Workflows to trigger it. In this case, you will not use Prefect scheduling. You can check <a href="https://cloud.google.com/blog/topics/developers-practitioners/long-running-containers-workflows-and-compute-engine">here</a> and <a href="https://medium.com/google-cloud/long-running-job-with-cloud-workflows-38b57bea74a5">here</a> to learn more.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can also interface with BigQuery, Storage, and Secret Manager via <code>prefect-gcp</code>.</p>
<p>The more scalable solution that most big companies with structured data teams do is to run the flow on <a href="https://docs.prefect.io/tutorials/_kubernetes-flow-runner/">Docker and Kubernetes</a>.</p>
<p>I also see that in Prefect 1.0, they have a solution to run the flow on VertexAI, which is the Google's serverless and managed service for machine learning. you can run the flow on VertexAI and configure the machine you use. After the flow is finished, the machine will turn off. But this feature is not ready for Prefect 2.0 yet and will be added soon.</p>
<p>Additionally, you may view the following videos to learn how to use Prefect on a VM on AWS:

</p>
<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ComkSIAB0k4" frameborder="0" allowfullscreen=""></iframe>
</center>

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/xw9JfaWPPps" frameborder="0" allowfullscreen=""></iframe>
</center>

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/oDSf0ThKsso" frameborder="0" allowfullscreen=""></iframe>
</center>


</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's it for this post. We will check ZenML in our next blog post.</p>
<p><strong>Note</strong>: I will update this post when I learn more about Prefect deployment on Cloud.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="kargarisaac/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/mlops/2022/08/09/machine-learning-workflow-orchestration-prefect.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My posts about Machine Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/kargarisaac" target="_blank" title="kargarisaac"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/eshagh-kargar" target="_blank" title="eshagh-kargar"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/kargarisaac" target="_blank" title="kargarisaac"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
